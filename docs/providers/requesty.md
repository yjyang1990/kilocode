# Requesty

Roo Code supports accessing models through the [Requesty](https://www.requesty.ai/) AI platform. Requesty provides a unified API for interacting with various large language models (LLMs), including those from Anthropic and OpenAI, and offers features for testing, deploying, and monitoring LLM applications.  It's designed to simplify the process of integrating AI into applications.

**Website:** [https://www.requesty.ai/](https://www.requesty.ai/)

## Getting an API Key

1.  **Sign Up/Sign In:** Go to the [Requesty website](https://www.requesty.ai/) and create an account or sign in.
2.  **Get API Key:**  You can get an API key from the [API Management ](https://app.requesty.ai/manage-api) section of your Requesty dashboard.

## Supported Models

Requesty provides access to a wide range of models.  Roo Code will automatically fetch the latest list of available models. You can see the full list of available models on the [Model List](https://app.requesty.ai/router/list) page.

## Configuration in Roo Code

1.  **Open Roo Code Settings:** Click the gear icon (<Codicon name="gear" />) in the Roo Code panel.
2.  **Select Provider:** Choose "Requesty" from the "API Provider" dropdown.
3.  **Enter API Key:** Paste your Requesty API key into the "Requesty API Key" field.
4.  **Select Model:** Choose your desired model from the "Model" dropdown.
